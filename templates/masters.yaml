AWSTemplateFormatVersion: '2010-09-09'
Description: ASG for masters

Parameters:

    EnvironmentName:
      Description: An environment name that will be prefixed to resource names
      Type: String

    InstanceType:
        Description: Which instance type should we use?
        Type: String
        Default: t2.medium

    ClusterSize:
        Description: How many instances do you want to initially deploy?
        Type: Number
        Default: 3

    MaxSize:
        Description: Maximum size of ASG?
        Type: Number
        Default: 5

    VPC:
        Description: Choose which VPC this cluster should be deployed to
        Type: AWS::EC2::VPC::Id

    Subnets:
        Description: Choose which subnets this cluster should be deployed to
        Type: List<AWS::EC2::Subnet::Id>

    SecurityGroup:
        Description: Select the Security Group to use for the instances
        Type: List<AWS::EC2::SecurityGroup::Id>

    InstanceProfile:
        Description: InstanceProfile to use
        Type: String

    KeyName:
        Description: SSH keypair name
        Type: AWS::EC2::KeyPair::KeyName

    LoadBalancerUrl:
      Description: URL of ELB used for master's endpoint
      Type: String

Mappings:
  RegionToAMI:
    ap-northeast-1:
      standard: ami-3dbcb441
      min: ami-8bbab2f7
    ap-northeast-2:
      standard: ami-deb916b0
      min: ami-6db71803
    ap-northeast-3:
      standard: ami-2237395f
      min: ami-25373958
    ap-south-1:
      standard: ami-28560c47
      min: ami-24550f4b
    ap-southeast-1:
      standard: ami-4db5ec31
      min: ami-b4b0e9c8
    ap-southeast-2:
      standard: ami-6b62ae09
      min: ami-4462ae26
    ca-central-1:
      standard: ami-35ae2851
      min: ami-b2af29d6
    eu-central-1:
      standard: ami-104419fb
      min: ami-08471ae3
    eu-west-1:
      standard: ami-86c695ff
      min: ami-68c29111
    eu-west-2:
      standard: ami-598b6a3e
      min: ami-5b8b6a3c
    eu-west-3:
      standard: ami-f22c9a8f
      min: ami-af2b9dd2
    sa-east-1:
      standard: ami-a77225cb
      min: ami-1b7b2c77
    us-east-1:
      standard: ami-b270a8cf
      min: ami-3b74ac46
    us-east-2:
      standard: ami-9bc0f1fe
      min: ami-b0c6f7d5
    us-west-1:
      standard: ami-62405102
      min: ami-964352f6
    us-west-2:
      standard: ami-d2f06baa
      min: ami-7beb7003

Resources:

    LaunchConfiguration:
        Type: AWS::AutoScaling::LaunchConfiguration
        Properties:
            ImageId:  !FindInMap [RegionToAMI, !Ref "AWS::Region", min]
            InstanceType: !Ref InstanceType
            SecurityGroups: !Ref SecurityGroup
            IamInstanceProfile: !Ref InstanceProfile
            KeyName: !Ref KeyName
            UserData:
                "Fn::Base64": !Sub |
                    #!/bin/bash
                    cleanup () {
                      CODE=$?
                      /opt/aws/bin/cfn-signal -e $CODE --stack ${AWS::StackName} --resource AutoScalingGroup --region ${AWS::Region}
                      exit $CODE
                    }

                    trap "cleanup" INT TERM EXIT
                    set -ex

                    # Update system and install Docker and AWS cli
                    yum update -y
                    yum install -y awscli
                    yum install -y aws-cfn-bootstrap
                    yum install -y docker

                    # Get kube's binaries
                    PLATFORM=amd64
                    KUBE_RELEASE=v1.9.6
                    KUBE_URL=https://storage.googleapis.com/kubernetes-release/release

                    DIR=/usr/local/bin/
                    FILES="kubelet kubectl kube-proxy"

                    for FILE in $FILES; do
                      curl -sS --retry 3 "$KUBE_URL/$KUBE_RELEASE/bin/linux/$PLATFORM/$FILE" -o $DIR/$FILE
                      chmod +x $DIR/$FILE
                    done

                    DATA_DIR=/var/lib/etcd
                    mkdir -p $DATA_DIR

                    REGISTRY=quay.io/coreos/etcd
                    ETCD_VERSION=v3.2

                    INTERNAL_IP=$(curl -sS --retry 3 http://169.254.169.254/latest/meta-data/local-ipv4)
                    EC2_INSTANCE_ID=$(curl -sS --retry 3 http://169.254.169.254/latest/meta-data/instance-id)

                    export AWS_DEFAULT_REGION=${AWS::Region}

                    # Get ASG name the instance belong to
                    ASG_NAME=$(aws autoscaling describe-auto-scaling-instances --instance-ids $EC2_INSTANCE_ID --query AutoScalingInstances[0].AutoScalingGroupName --out text)

                    # Create query string to get all inService instances and desired state
                    QUERY="AutoScalingGroups[?AutoScalingGroupName==\`$ASG_NAME\`].{size:DesiredCapacity,instances:Instances[?LifecycleState==\`InService\`].InstanceId}"
                    DESIRED_SIZE=0
                    ACTUAL_SIZE=0

                    # Wait until ASG launch all instances with retry and back-off strategy
                    for i in `seq 1 10`
                    do
                      # Query all inService instances and desired state and get desired number of instances
                      ASG_DATA=$(aws autoscaling describe-auto-scaling-groups --auto-scaling-group-name $ASG_NAME --query $QUERY  --output text)
                      DESIRED_SIZE=$(echo "$ASG_DATA" | head -1)
                      ACTUAL_SIZE=$(echo "$ASG_DATA" | grep -ci instance)
                      # go out of cycle if the number of instances match the desired state
                      [ $ACTUAL_SIZE -eq $DESIRED_SIZE ] && break
                      # otherwise wait and try again
                      echo "wait till all instances are InService"
                      sleep $((i*3))
                    done

                    # Final test that ASG has been stabilized (because there are two exits from 'for' loop)
                    [ $ACTUAL_SIZE -eq $DESIRED_SIZE ] || (echo "ASG hasn't stabilized"; exit 1)

                    INSTANCES=$(echo "$ASG_DATA" | grep -i instance | awk '{print $2}')
                    ETCD_INITIAL_CLUSTER=$(aws ec2 describe-instances --instance-ids $INSTANCES --query 'Reservations[].Instances[].[InstanceId,PrivateIpAddress]' --output text | sort | awk '{ printf("%s=https://%s:2380,", $1, $2) }' | sed 's/,$//g')

                    cat > /etc/systemd/system/etcd.service <<EOF
                    [Unit]
                    Description=etcd
                    After=docker.service
                    Requires=docker.service
                    Documentation=https://github.com/coreos

                    [Service]
                    TimeoutStartSec=0
                    ExecStartPre=/usr/bin/docker pull $REGISTRY:$ETCD_VERSION
                    ExecStart=/usr/bin/docker run \\
                      -p 2379:2379 \\
                      -p 2380:2380 \\
                      --net host \\
                      --volume=$DATA_DIR:/etcd-data \\
                      --name etcd $REGISTRY:$ETCD_VERSION \\
                      /usr/local/bin/etcd \\
                        --data-dir=/etcd-data --name $EC2_INSTANCE_ID \\
                        --initial-advertise-peer-urls https://$INTERNAL_IP:2380 \\
                        --listen-peer-urls https://$INTERNAL_IP:2380 \\
                        --advertise-client-urls https://$INTERNAL_IP:2379,http://127.0.0.1:2379 \\
                        --listen-client-urls https://$INTERNAL_IP:2379,http://127.0.0.1:2379 \\
                        --initial-cluster $ETCD_INITIAL_CLUSTER \\
                        --initial-cluster-state new --initial-cluster-token $ASG_NAME \\
                        --auto-tls \\
                        --peer-auto-tls

                    ExecStop=/usr/bin/docker stop etcd
                    ExecStopPost=/usr/bin/docker rm -f etcd
                    ExecReload=/usr/bin/docker restart etcd
                    Restart=always
                    RestartSec=10
                    Type=notify
                    NotifyAccess=all

                    [Install]
                    WantedBy=multi-user.target
                    EOF

                    ################## Kubernetes initialication ##############
                    CONFIG_DIR=/etc/kubernetes
                    MANIFEST_DIR=$CONFIG_DIR/manifests
                    CA_DIR=$CONFIG_DIR/pki
                    CNI_CONFIG_DIR=/etc/cni/
                    CNI_BIN_DIR=/opt/cni/bin

                    mkdir -p $CONFIG_DIR
                    mkdir -p $MANIFEST_DIR
                    mkdir -p $CA_DIR
                    mkdir -p $CA_DIR/private
                    mkdir -p $CNI_CONFIG_DIR/net.d
                    mkdir -p $CNI_BIN_DIR

                    ### get certificates
                    aws ssm get-parameters --name "/${EnvironmentName}/ca/ca" --query Parameters[0].Value --output text > $CA_DIR/ca.pem
                    aws ssm get-parameters --name "/${EnvironmentName}/ca/master" --query Parameters[0].Value --output text > $CA_DIR/master.pem
                    aws ssm get-parameters --name "/${EnvironmentName}/ca/private/master" --with-decryption --query Parameters[0].Value --output text > $CA_DIR/private/master.pem

                    ### Configure Kubelet
                    ## Create config file
                    cat > $CONFIG_DIR/kubeconfig <<EOF
                    apiVersion: v1
                    kind: Config
                    clusters:
                    - cluster:
                        certificate-authority: $CA_DIR/ca.pem
                        server: ${LoadBalancerUrl}
                      name: ${EnvironmentName}
                    contexts:
                    - context:
                        cluster: ${EnvironmentName}
                        user: kubelet
                      name: kubelet
                    current-context: kubelet
                    users:
                    - name: kubelet
                      user:
                        auth-provider:
                          config:
                            cluster-id: ${EnvironmentName}
                          name: aws
                    EOF

                    ## create systemd service file
                    cat > /etc/systemd/system/kubelet.service <<EOF
                    [Unit]
                    Description=Kubernetes Kubelet Server
                    Documentation=https://kubernetes.io/docs/concepts/overview/components/#kubelet https://kubernetes.io/docs/reference/generated/kubelet/
                    After=docker.service
                    Requires=docker.service

                    [Service]
                    TimeoutStartSec=5
                    ExecStartPre=/bin/mkdir -p /var/lib/kubelet
                    ExecStartPre=/bin/mount --bind /var/lib/kubelet /var/lib/kubelet
                    ExecStartPre=/bin/mount --make-shared /var/lib/kubelet
                    ExecStart=/usr/bin/docker run \\
                        --net=host \\
                        --pid=host \\
                        --privileged \\
                        -v /dev:/dev \\
                        -v /sys:/sys:ro \\
                        -v /var/run:/var/run:rw \\
                        -v /var/lib/docker/:/var/lib/docker:rw \\
                        -v /var/lib/kubelet/:/var/lib/kubelet:shared \\
                        -v /var/log:/var/log:shared \\
                        -v $CONFIG_DIR:/etc/kubernetes:ro \\
                        k8s.gcr.io/hyperkube:$KUBE_RELEASE kubelet \\
                            --address=0.0.0.0 \\
                            --node-ip=$INTERNAL_IP \\
                            --allow-privileged=true \\
                            --cloud-provider=aws \\
                            --cluster-dns=10.100.0.10 \\
                            --cluster-domain=cluster.local \\
                            --network-plugin=cni \\
                            --cni-bin-dir=/opt/cni/bin \\
                            --cni-conf-dir=/etc/cni/net.d \\
                            --container-runtime=docker \\
                            --cgroup-driver=cgroupfs \\
                            --register-node=true \\
                            --kubeconfig=$CONFIG_DIR/kubeconfig \\
                            --anonymous-auth=false \\
                            --client-ca-file=$CA_DIR/ca.pem \\
                            --authentication-token-webhook \\
                            --pod-manifest-path=$MANIFEST_DIR
                    KillMode=process
                    Restart=on-failure
                    RestartSec=5

                    [Install]
                    WantedBy=multi-user.target
                    EOF

                    systemctl daemon-reload
                    systemctl enable docker
                    systemctl start docker
                    systemctl enable kubelet
                    systemctl start kubelet
                    systemctl enable etcd
                    systemctl start etcd

    AutoScalingGroup:
        Type: AWS::AutoScaling::AutoScalingGroup
        CreationPolicy:
            ResourceSignal:
                Timeout: PT10M
        Properties:
            VPCZoneIdentifier: !Ref Subnets
            LaunchConfigurationName: !Ref LaunchConfiguration
            MinSize: !Ref ClusterSize
            MaxSize: !Ref MaxSize
            DesiredCapacity: !Ref ClusterSize
            Tags:
                - Key: Environment
                  Value: !Ref EnvironmentName
                  PropagateAtLaunch: true
                - Key: Network
                  Value: Control
                  PropagateAtLaunch: true
                - Key: Name
                  Value: !Sub '${EnvironmentName}-control-node'
                  PropagateAtLaunch: true
                  # kubelet specific tag to define cluster name  https://goo.gl/gdXPXu
                - Key: !Sub kubernetes.io/cluster/${EnvironmentName}
                  Value: owned
                  PropagateAtLaunch: true
